{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video to Podcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -qU pytubefix moviepy openai-whisper langchain langchain-text-splitters langchain-core langchain-community lancedb langchain-openai tiktoken openai python-dotenv azure-cognitiveservices-speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Have You Picked the Wrong AI Agent Framework?'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytubefix import YouTube\n",
    "from moviepy.editor import VideoFileClip\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# link of the video to be downloaded\n",
    "# yt = YouTube('https://www.youtube.com/watch?v=8N9L-XK1eEU')\n",
    "# yt = YouTube('https://www.youtube.com/watch?v=hJllkhC5GZU')\n",
    "# yt = YouTube('https://www.youtube.com/watch?v=KKWPSkYN3vw')\n",
    "# yt = YouTube('https://www.youtube.com/watch?v=8MMoBiIj9hI')\n",
    "yt = YouTube('https://www.youtube.com/watch?v=jLVl5V8roMU')\n",
    "\n",
    "yt.title\n",
    "\n",
    "# Get all streams and filter for mp4 files\n",
    "# yt.streams\n",
    "# ... .filter(progressive=True, file_extension='mp4')\n",
    "# ... .order_by('resolution')\n",
    "# ... .asc()\n",
    "# ... .first()\n",
    "# ... .download()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ffmpeg required for Whisper\n",
    "\n",
    "Install ffmpeg\n",
    "\n",
    "```\n",
    "sudo apt update && sudo apt install ffmpeg\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = yt.streams.filter(progressive=True, file_extension='mp4').order_by('resolution').desc().first().download()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = yt.title\n",
    "url = yt.watch_url\n",
    "description = yt.description\n",
    "thumbnail_url = yt.thumbnail_url\n",
    "\n",
    "# Escape description and replace newlines with \\n\n",
    "escaped_description = description.replace('\\n', '\\\\n').replace('\"', '\\\\\"')\n",
    "\n",
    "# Write a file with all the information about the video as a json\n",
    "info_file_name = fileName.split('.')[0] + '_info.json'\n",
    "with open(info_file_name, 'w') as f:\n",
    "    f.write(f'{{\"title\": \"{title}\", \"url\": \"{url}\", \"description\": \"{escaped_description}\", \"thumbnail_url\": \"{thumbnail_url}\"}}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are you diving into the world of agent-based AI workflows and finding it more complicated than it needs to be? You’ve probably chosen the wrong approach, burdened with verbose, time-consuming frameworks. In this video, I’ll show you a far easier method to build your AI workflow, cutting through the unnecessary boilerplate and complexity.\n",
      "\n",
      "Using CrewAI as an example, inspired by Code with Brandon’s excellent tutorials, we’ll explore how to streamline your processes. Watch as I automate a YouTube strategy in just seconds, a task that would typically take hours. Whether you’re a YouTuber or have daily repetitive tasks, this video will show you how to simplify and enhance your workflow with ease.\n",
      "\n",
      "Join me as we debunk the myth that AI workflows are inherently complex. We’ll contrast CrewAI’s traditional method with a more efficient solution using Typescript and BunJS, reducing hundreds of lines of code to just a few dozen. Discover how you can achieve the same results with less effort and fewer headaches.\n",
      "\n",
      "Don’t miss out on this game-changing approach to AI automation. Subscribe, hit the bell icon, and dive into the video to revolutionize your AI workflow today. And for more exclusive insights and updates, be sure to subscribe to my newsletter at technovangelist.com/newsletter and join my Patreon community at patreon.com/technovangelist.\n",
      "\n",
      "In this video I mention:\n",
      "\n",
      "dirty-json: https://github.com/RyanMarcus/dirty-json\n",
      "\n",
      "\n",
      "You can find the code for every video I make at https://github.com/technovangelist/videoprojects. Then find the folder name that starts with the date this video was published and a title that makes sense for what the video covers. \n",
      "\n",
      "Be sure to sign up to my monthly newsletter at https://technovangelist.substack.com/subscribe\n",
      "\n",
      "I have a Patreon at https://patreon.com/technovangelist\n",
      "\n",
      "You can find the Technovangelist discord at: https://discord.gg/9sS4HppS\n",
      "The Ollama discord is at https://discord.gg/ollama\n",
      "\n",
      "(they have a pretty url because they are paying at least $100 per month for Discord. You help get more viewers to this channel and I can afford that too.)\n"
     ]
    }
   ],
   "source": [
    "print(yt.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the file name for the audio file\n",
    "audioFileName = fileName.split('.')[0] + '.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in /home/pmalarme/workspace/drop-all/Have You Picked the Wrong AI Agent Framework.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "video = VideoFileClip(fileName)\n",
    "audio = video.audio\n",
    "audio.write_audiofile(audioFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup: delete the video file\n",
    "video.close()\n",
    "os.remove(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The agent-based workflow is one of the hottest trends in the AI world right now. And if you are building one, you've probably chosen the wrong way to build it. And by wrong, I mean more verbose, more complicated, and more time-consuming. The framework's out there. Want you to think that this stuff is hard, but it's not. In this video, I'm going to show you how to build one far easier than any other tutorial out on YouTube right now. Most of the tools out there require reams of repetitive boilerplate that has little need to actually be there. In most cases, you can do it a lot more simply, and again, in this video, I'm going to remind you of an easier way to get the same thing done. You're probably going to smack yourself on the forehead when you see how easy this can be in most cases. Now, let's get right to it and take a look at an example using Crew AI. I saw this tutorial by Code with Brandon, and it does a great job. In fact, all the videos on his channel are really well done, and you should check them out. In this one, he shows how to use Crew to automate components of his YouTube strategy. He researches topics, comes up with possible titles in the description, and perhaps an email to send out to subscribers. This is potentially an hour or two of work condensed down and completed in seconds. That's amazing. You may not be a YouTuber, but you have processes that you do every day that could be automated just like this. This has been the promise of AI and agents since the very beginning, and it's one of the reasons why people are really excited. Have the robots do your work. But there are a few problems with this. Let's take a look at the code. In the main Python file, we see that we define some agents and tasks, and here we're assigning tasks to agents, and then we're kicking off the app. So the way most of these systems work is that they have agents that manage stuff, kind of like people in a team at any company. And just like those people in a team, they perform various tasks. And so with Crew and other frameworks, we model those same concepts. But for most workflows that you're going to automate, these tend to have a one-to-one relationship, rather than the many-to-many relationship they're capable of. In Brandon's example, there are four tasks, and one agent for each. And Brandon isn't alone. Most of the examples I've seen by others, and or even in the crew examples, repo tends to do the exact same thing. So if most workflows are going to do that, then having to define an agent and a task is just extra work with no real value. But even if you did have one agent performing multiple tasks, the goals and backstories you need to create tend to be a bit ambiguous. And in many cases, just confuse the model rather than help make a better agent flow. But I don't think that is even my biggest gripe with these frameworks. In most of the examples, there is a well-defined workflow that we're trying to automate. But rather than use that workflow, we're creating a manager agent which comes up with the workflow on its own. Sometimes it does, and sometimes it doesn't. But every time it takes a little bit of extra time to complete. Now you might respond that if you use ChatGee BT, it's hardly any time at all. But then we get all the security and privacy issues that you probably already know about. So that's not really a viable answer for a lot of folks out there. And then maybe the language you're strongest at is Rust or Go or TypeScript or something else. For no good reason, many of these frameworks require Python, which is its own set of problems. Already early on, Olama switched from Python to Go to make things easier and more powerful. But there's no reason that you as a user needs to know about that. I've seen the same progression for so many projects out there. The first two issues coming up with the workflow and the Verbrose agent task definitions show that in many situations, in the cases of most of the examples out there, this is the wrong tool for the job. And that's a common pattern with any newer technology. We've seen this so many times over and over again all over the place. Spinning up Kubernetes when you just need to host a single website on one machine is the wrong tool for the job. Using Langchain when you just need to write a simple rag solution is the wrong tool for the job. Using out your Dremel when you need to get rid of a nail, you hammer. Did I mention we caught the Dremel multi-brow? Oh, it's a wrong tool for the job. All of these Kubernetes, Langchain and the Dremel are the right tool when you're using them for the right thing. The right thing in the case of crew AI or other agent frameworks is when you have a job that doesn't have a well-defined workflow where you need the model to do something close to reasoning and understanding to solve it. But that's the situation in a small minority of use cases. Now some will say that even if you know the workflow of a much more complex project, crew would be the right solution, but I don't think so. It's always going to be easier and more scalable by keeping it simple and using something like a state machine library like X-Tate to manage the flow. So let's take a look at an alternative to using crew to automate one of the workflows that we have. Now I am also a YouTuber so I'm going to go ahead and automate what Brandon did. I'll be doing this with TypeScript and BunJS. Now first, let's run the app. YT Research. It takes in a topic which I've set to AI models local Olamah. And then it searches on YouTube for relevant videos that have done really well. It actually finds 50 videos and then I sort them based on a kind of an arbitrary formula. For each video, I have days since published, views, likes and number of comments. I normalize the views by subscribers and likes and comments by views. The views is more important than the likes and the likes are more important than comments. And newer videos rank higher than older ones. So I divide by days since published. That formula looks like this. So then I take the top 15 of the videos found and format them as Brandon did in his video. Next I take the topic I set above along with a short description I created of what I thought I was about making along with this list of 15 well performing titles and I have a model come up with 10 good titles for my potential video. Next I use the topic and description to make a more filled out description which also points to my newsletter which you can find at Technovangelis.com slash newsletter and my Patreon which you can find at patreon.com slash Technovangelis. Finally I use that description to come up with an email to my newsletter subscribers announcing the new video. Running the whole process takes less than 90 seconds. That is far less time than it takes me to come up with one really bad title for my videos. I fumble around creating a description and they never sound as good as this one. And I never even thought of sending an email to my subs so I'll definitely be doing that in the future. Now using crew to perform this same workflow took about 450 lines or so of code not including the code required to interact with the YouTube API. Sure there are comments and spacing to make it easy to read so let's just say 300 lines of code. Let's take a look at my version. At the top I have some imports. The two external dependencies are Olamma and a package called dirty json which makes it easier to deal with json embedded in json. Then I pull in the functions for searching YouTube collecting input from my user and my prompts. So let's get the search results from the YouTube API. It pulls 50 of them which have been assigned a score by me. So I sort by that score and then I print out the output. Before moving on let's take a quick look at that code. Breaching out to the YouTube API. Video search tool makes a call out to the YouTube API with the topic my API key and the number of results that I need. Then it pulls out the pieces I need and returns an array of all the videos. To get the stats I need to call video details tool on that same video and that gets me all that stuff. Then I generate a string based on the format of the report brand and wanted. And here we can see the score I assigned to it. Finally I return an array of the stats, the report string and the score. Okay, so now back to the main script. I can make a call to Olamma generate and set a system prompt and user prompt. That user prompt tells the model the topic description and a list of well performing titles as well as the JSON template to use. Now I'm using function calling here because this is an application that's going to use the output later on. I could have defined all the functions that could be used and let the model choose but I know which function is needed for this. So there's no reason to do that. That spits out my JSON object of titles which I can parse and display. Now I'm using the generate endpoint instead of the chat endpoint because these are one off calls to Olamma. And now I don't want to deal with the hassle of using messages object since it doesn't give me any benefit here. So then I can call it generate again passing in the topic and my short description to have it build a more complete description. Again I'm using function calling to output a well formed JSON object. I set the system prompts for all of these from my prompts file shown here. You can see that I have a prompt for coming up with titles, the description and the email. Now the output here was a bit strange because there are a bunch of new lines in my JSON. My code had a hard time dealing with it so the really cool dirty JSON package helped a lot here. Finally I use the new description and my topic to come up with an email to send to users. If I provided it with the URL to this video this would be even more complete. So not including the tool code this comes to about 60 lines of code. That's a big saving over the 450, sorry, we agreed to say that it was 300. 300 lines of code required to use crew to perform exactly the same process. Less code often but not always means fewer bugs and easier to write and faster to just get stuff done. As I mentioned before there are probably cases where crew AI is potentially useful but even those times there may be something easier. I am so glad I saw that video from code with Brandon. I plan to implement a workflow just like this for my own channel. Coming up with the tweets and LinkedIn posts and the description and more can be super powerful and save me a lot of time. Maybe after I finalize my own process I can share it on here with all of you. I look forward to seeing projects like crew AI mature a bit more. Right now it feels a bit too much like when I did early Windows program with that Charles Petzold book opened up in front of me typing out pages of boilerplate to get the simplest hello world on Windows 3-1-1. What do you think? Are you automating your own workflows with AI? How are you doing it? I would love to hear your feedback in the comments below. I am sure this one is going to generate a lot of comments calling me an idiot. What happened for the function calling one two? No one was actually able to show that I got anything wrong in that one. I hope that in a few months this video becomes out of date because the frameworks do a better job. Who knows? Well, I mentioned the newsletter in the Patreon earlier in the video so I can just get to the straight to the 20 seconds of silence, some call awkward silence, that quite a few of you really love. Thanks so much for watching. Goodbye.\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model('base')\n",
    "result = model.transcribe(audioFileName)\n",
    "\n",
    "print(result['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup: delete the audio file\n",
    "os.remove(audioFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the transcript\n",
    "transcriptFileName = fileName.split('.')[0] + '.txt'\n",
    "with open(transcriptFileName, \"w\") as f:\n",
    "    f.write(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Given title and description of a video, can you check its transcript and correct it. Give back only the corrected transcript.\n",
    "\n",
    "Title: {title}\n",
    "Description:\n",
    "{description}\n",
    "\n",
    "Transcript:\n",
    "{transcript}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read .env file\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "\n",
    "azure_openai_client = AzureOpenAI(\n",
    "  api_key=os.environ['OPENAI_API_KEY'],\n",
    "  azure_endpoint=os.environ['OPENAI_AZURE_ENDPOINT'],\n",
    "  # azure_deployment=os.environ['OPENAI_AZURE_DEPLOYMENT'],\n",
    "  api_version=os.environ['OPENAI_API_VERSION']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    encoding = tiktoken.encoding_for_model(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "    \n",
    "\n",
    "encoding_name = 'gpt-4o'\n",
    "\n",
    "# Split the text in chunks of maximum 500 tokens with '.' as separator without using langchain\n",
    "sentences = result['text'].split('.')\n",
    "chunks = []\n",
    "chunk = ''\n",
    "chunk_number = 1\n",
    "for sentence in sentences:\n",
    "    if num_tokens_from_string(chunk + sentence, encoding_name) > 500:\n",
    "        prompt = prompt_template.format(title=title, description=description, transcript=chunk)\n",
    "        corrected_chunk = azure_openai_client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            temperature=0,\n",
    "            top_p=1,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "        ).choices[0].message.content\n",
    "        chunks.append(corrected_chunk)\n",
    "        #  # Write the file\n",
    "        # chunk_file_name = fileName.split('.')[0] + '_chunk_' + str(chunk_number) + '.txt'\n",
    "        # with open(chunk_file_name, \"w\") as f:\n",
    "        #     f.write(chunk)\n",
    "        # corrected_chunk_file_name = fileName.split('.')[0] + '_chunk_' + str(chunk_number) + '_corrected.txt'\n",
    "        # with open(corrected_chunk_file_name, \"w\") as f:\n",
    "        #     f.write(corrected_chunk)\n",
    "        chunk = sentence + '. '\n",
    "        chunk_number += 1\n",
    "    else:\n",
    "        chunk += sentence + '. '\n",
    "        \n",
    "# Write the last chunk\n",
    "prompt = prompt_template.format(title=title, description=description, transcript=chunk)\n",
    "corrected_chunk = azure_openai_client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0,\n",
    "    top_p=1,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ],\n",
    ").choices[0].message.content\n",
    "chunks.append(corrected_chunk)\n",
    "# # Write the file\n",
    "# chunk_file_name = fileName.split('.')[0] + '_chunk_' + str(chunk_number) + '.txt'\n",
    "# with open(chunk_file_name, \"w\") as f:\n",
    "#     f.write(chunk)\n",
    "# corrected_chunk_file_name = fileName.split('.')[0] + '_chunk_' + str(chunk_number) + '_corrected.txt'\n",
    "# with open(corrected_chunk_file_name, \"w\") as f:\n",
    "#     f.write(corrected_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the full corrected transcript and add whitelines between the chunks but not for the last chunk\n",
    "full_corrected_transcript = ''\n",
    "for i, chunk in enumerate(chunks):\n",
    "    full_corrected_transcript += chunk\n",
    "    if i < len(chunks) - 1:\n",
    "        full_corrected_transcript += '\\n\\n'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the full corrected transcript\n",
    "full_corrected_transcript_file_name = fileName.split('.')[0] + '_corrected.txt'\n",
    "with open(full_corrected_transcript_file_name, \"w\") as f:\n",
    "    f.write(full_corrected_transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create langchain document\n",
    "from langchain_core.documents.base import Document\n",
    "\n",
    "document = Document(\n",
    "  page_content=full_corrected_transcript,\n",
    "  metadata={\n",
    "    \"title\": title,\n",
    "    \"source\": url,\n",
    "    \"description\": description,\n",
    "    \"thumbnail_url\": thumbnail_url\n",
    "  }\n",
    ")\n",
    "\n",
    "documents = [document]  # List of documents to be processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "  chunk_size=1000,\n",
    "  chunk_overlap=200\n",
    ")\n",
    "splits = text_splitter.split_documents(documents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "azure_openai_embeddings = AzureOpenAIEmbeddings(\n",
    "  api_key=os.environ['OPENAI_API_KEY'],\n",
    "  azure_endpoint=os.environ['OPENAI_AZURE_ENDPOINT'],\n",
    "  api_version=os.environ['OPENAI_API_VERSION'],\n",
    "  azure_deployment=os.environ['OPENAI_AZURE_DEPLOYMENT_EMBEDDINGS']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import LanceDB\n",
    "\n",
    "vectorstore = LanceDB.from_documents(\n",
    "  documents=splits,\n",
    "  embedding=azure_openai_embeddings\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lancedb\n",
    "\n",
    "db = lancedb.connect(\"/tmp/lancedb\")\n",
    "# table = db.create_table(\n",
    "#     \"my_table\",\n",
    "#     data=[\n",
    "#         {\n",
    "#             \"vector\": embeddings.embed_query(\"Hello World\"),\n",
    "#             \"text\": \"Hello World\",\n",
    "#             \"id\": \"1\",\n",
    "#         }\n",
    "#     ],\n",
    "#     mode=\"overwrite\",\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'description': 'Are you diving into the world of agent-based AI workflows and finding it more complicated than it needs to be? You’ve probably chosen the wrong approach, burdened with verbose, time-consuming frameworks. In this video, I’ll show you a far easier method to build your AI workflow, cutting through the unnecessary boilerplate and complexity.\\n\\nUsing CrewAI as an example, inspired by Code with Brandon’s excellent tutorials, we’ll explore how to streamline your processes. Watch as I automate a YouTube strategy in just seconds, a task that would typically take hours. Whether you’re a YouTuber or have daily repetitive tasks, this video will show you how to simplify and enhance your workflow with ease.\\n\\nJoin me as we debunk the myth that AI workflows are inherently complex. We’ll contrast CrewAI’s traditional method with a more efficient solution using Typescript and BunJS, reducing hundreds of lines of code to just a few dozen. Discover how you can achieve the same results with less effort and fewer headaches.\\n\\nDon’t miss out on this game-changing approach to AI automation. Subscribe, hit the bell icon, and dive into the video to revolutionize your AI workflow today. And for more exclusive insights and updates, be sure to subscribe to my newsletter at technovangelist.com/newsletter and join my Patreon community at patreon.com/technovangelist.\\n\\nIn this video I mention:\\n\\ndirty-json: https://github.com/RyanMarcus/dirty-json\\n\\n\\nYou can find the code for every video I make at https://github.com/technovangelist/videoprojects. Then find the folder name that starts with the date this video was published and a title that makes sense for what the video covers. \\n\\nBe sure to sign up to my monthly newsletter at https://technovangelist.substack.com/subscribe\\n\\nI have a Patreon at https://patreon.com/technovangelist\\n\\nYou can find the Technovangelist discord at: https://discord.gg/9sS4HppS\\nThe Ollama discord is at https://discord.gg/ollama\\n\\n(they have a pretty url because they are paying at least $100 per month for Discord. You help get more viewers to this channel and I can afford that too.)', 'source': 'https://youtube.com/watch?v=jLVl5V8roMU', 'thumbnail_url': 'https://i.ytimg.com/vi/jLVl5V8roMU/sddefault.jpg', 'title': 'Have You Picked the Wrong AI Agent Framework?'}, page_content=\"Using Langchain when you just need to write a simple RAG solution is the wrong tool for the job. It's like using your Dremel when you need to get rid of a nail; you use a hammer. Did I mention we call the Dremel multi-pro? Oh, it's the wrong tool for the job. All of these—Kubernetes, Langchain, and the Dremel—are the right tools when you're using them for the right thing. The right thing in the case of CrewAI or other agent frameworks is when you have a job that doesn't have a well-defined workflow where you need the model to do something close to reasoning and understanding to solve it. But that's the situation in a small minority of use cases.\"),\n",
       " Document(metadata={'description': 'Are you diving into the world of agent-based AI workflows and finding it more complicated than it needs to be? You’ve probably chosen the wrong approach, burdened with verbose, time-consuming frameworks. In this video, I’ll show you a far easier method to build your AI workflow, cutting through the unnecessary boilerplate and complexity.\\n\\nUsing CrewAI as an example, inspired by Code with Brandon’s excellent tutorials, we’ll explore how to streamline your processes. Watch as I automate a YouTube strategy in just seconds, a task that would typically take hours. Whether you’re a YouTuber or have daily repetitive tasks, this video will show you how to simplify and enhance your workflow with ease.\\n\\nJoin me as we debunk the myth that AI workflows are inherently complex. We’ll contrast CrewAI’s traditional method with a more efficient solution using Typescript and BunJS, reducing hundreds of lines of code to just a few dozen. Discover how you can achieve the same results with less effort and fewer headaches.\\n\\nDon’t miss out on this game-changing approach to AI automation. Subscribe, hit the bell icon, and dive into the video to revolutionize your AI workflow today. And for more exclusive insights and updates, be sure to subscribe to my newsletter at technovangelist.com/newsletter and join my Patreon community at patreon.com/technovangelist.\\n\\nIn this video I mention:\\n\\ndirty-json: https://github.com/RyanMarcus/dirty-json\\n\\n\\nYou can find the code for every video I make at https://github.com/technovangelist/videoprojects. Then find the folder name that starts with the date this video was published and a title that makes sense for what the video covers. \\n\\nBe sure to sign up to my monthly newsletter at https://technovangelist.substack.com/subscribe\\n\\nI have a Patreon at https://patreon.com/technovangelist\\n\\nYou can find the Technovangelist discord at: https://discord.gg/9sS4HppS\\nThe Ollama discord is at https://discord.gg/ollama\\n\\n(they have a pretty url because they are paying at least $100 per month for Discord. You help get more viewers to this channel and I can afford that too.)', 'source': 'https://youtube.com/watch?v=jLVl5V8roMU', 'thumbnail_url': 'https://i.ytimg.com/vi/jLVl5V8roMU/sddefault.jpg', 'title': 'Have You Picked the Wrong AI Agent Framework?'}, page_content=\"examples, there is a well-defined workflow that we're trying to automate. But rather than use that workflow, we're creating a manager agent which comes up with the workflow on its own. Sometimes it does, and sometimes it doesn't. But every time it takes a little bit of extra time to complete. Now you might respond that if you use ChatGPT, it's hardly any time at all. But then we get all the security and privacy issues that you probably already know about. So that's not really a viable answer for a lot of folks out there. And then maybe the language you're strongest at is Rust or Go or TypeScript or something else. For no good reason, many of these frameworks require Python, which is its own set of problems. Already early on, Ollama switched from Python to Go to make things easier and more powerful. But there's no reason that you as a user need to know about that. I've seen the same progression for so many projects out there. The first two issues—coming up with the workflow and the\"),\n",
       " Document(metadata={'description': 'Are you diving into the world of agent-based AI workflows and finding it more complicated than it needs to be? You’ve probably chosen the wrong approach, burdened with verbose, time-consuming frameworks. In this video, I’ll show you a far easier method to build your AI workflow, cutting through the unnecessary boilerplate and complexity.\\n\\nUsing CrewAI as an example, inspired by Code with Brandon’s excellent tutorials, we’ll explore how to streamline your processes. Watch as I automate a YouTube strategy in just seconds, a task that would typically take hours. Whether you’re a YouTuber or have daily repetitive tasks, this video will show you how to simplify and enhance your workflow with ease.\\n\\nJoin me as we debunk the myth that AI workflows are inherently complex. We’ll contrast CrewAI’s traditional method with a more efficient solution using Typescript and BunJS, reducing hundreds of lines of code to just a few dozen. Discover how you can achieve the same results with less effort and fewer headaches.\\n\\nDon’t miss out on this game-changing approach to AI automation. Subscribe, hit the bell icon, and dive into the video to revolutionize your AI workflow today. And for more exclusive insights and updates, be sure to subscribe to my newsletter at technovangelist.com/newsletter and join my Patreon community at patreon.com/technovangelist.\\n\\nIn this video I mention:\\n\\ndirty-json: https://github.com/RyanMarcus/dirty-json\\n\\n\\nYou can find the code for every video I make at https://github.com/technovangelist/videoprojects. Then find the folder name that starts with the date this video was published and a title that makes sense for what the video covers. \\n\\nBe sure to sign up to my monthly newsletter at https://technovangelist.substack.com/subscribe\\n\\nI have a Patreon at https://patreon.com/technovangelist\\n\\nYou can find the Technovangelist discord at: https://discord.gg/9sS4HppS\\nThe Ollama discord is at https://discord.gg/ollama\\n\\n(they have a pretty url because they are paying at least $100 per month for Discord. You help get more viewers to this channel and I can afford that too.)', 'source': 'https://youtube.com/watch?v=jLVl5V8roMU', 'thumbnail_url': 'https://i.ytimg.com/vi/jLVl5V8roMU/sddefault.jpg', 'title': 'Have You Picked the Wrong AI Agent Framework?'}, page_content=\"description. Again, I'm using function calling to output a well-formed JSON object. I set the system prompts for all of these from my prompts file shown here. You can see that I have a prompt for coming up with titles, the description, and the email. Now the output here was a bit strange because there are a bunch of new lines in my JSON. My code had a hard time dealing with it, so the really cool dirty-json package helped a lot here. Finally, I use the new description and my topic to come up with an email to send to users. If I provided it with the URL to this video, this would be even more complete. So not including the tool code, this comes to about 60 lines of code. That's a big saving over the 450, sorry, we agreed to say that it was 300. 300 lines of code required to use CrewAI to perform exactly the same process. Less code often, but not always, means fewer bugs and easier to write and faster to just get stuff done. As I mentioned before, there are probably cases where CrewAI is\"),\n",
       " Document(metadata={'description': 'Are you diving into the world of agent-based AI workflows and finding it more complicated than it needs to be? You’ve probably chosen the wrong approach, burdened with verbose, time-consuming frameworks. In this video, I’ll show you a far easier method to build your AI workflow, cutting through the unnecessary boilerplate and complexity.\\n\\nUsing CrewAI as an example, inspired by Code with Brandon’s excellent tutorials, we’ll explore how to streamline your processes. Watch as I automate a YouTube strategy in just seconds, a task that would typically take hours. Whether you’re a YouTuber or have daily repetitive tasks, this video will show you how to simplify and enhance your workflow with ease.\\n\\nJoin me as we debunk the myth that AI workflows are inherently complex. We’ll contrast CrewAI’s traditional method with a more efficient solution using Typescript and BunJS, reducing hundreds of lines of code to just a few dozen. Discover how you can achieve the same results with less effort and fewer headaches.\\n\\nDon’t miss out on this game-changing approach to AI automation. Subscribe, hit the bell icon, and dive into the video to revolutionize your AI workflow today. And for more exclusive insights and updates, be sure to subscribe to my newsletter at technovangelist.com/newsletter and join my Patreon community at patreon.com/technovangelist.\\n\\nIn this video I mention:\\n\\ndirty-json: https://github.com/RyanMarcus/dirty-json\\n\\n\\nYou can find the code for every video I make at https://github.com/technovangelist/videoprojects. Then find the folder name that starts with the date this video was published and a title that makes sense for what the video covers. \\n\\nBe sure to sign up to my monthly newsletter at https://technovangelist.substack.com/subscribe\\n\\nI have a Patreon at https://patreon.com/technovangelist\\n\\nYou can find the Technovangelist discord at: https://discord.gg/9sS4HppS\\nThe Ollama discord is at https://discord.gg/ollama\\n\\n(they have a pretty url because they are paying at least $100 per month for Discord. You help get more viewers to this channel and I can afford that too.)', 'source': 'https://youtube.com/watch?v=jLVl5V8roMU', 'thumbnail_url': 'https://i.ytimg.com/vi/jLVl5V8roMU/sddefault.jpg', 'title': 'Have You Picked the Wrong AI Agent Framework?'}, page_content='Right now it feels a bit too much like when I did early Windows programming with that Charles Petzold book opened up in front of me, typing out pages of boilerplate to get the simplest \"Hello, World!\" on Windows 3.1. What do you think? Are you automating your own workflows with AI? How are you doing it? I would love to hear your feedback in the comments below. I am sure this one is going to generate a lot of comments calling me an idiot. What happened with the function calling one too? No one was actually able to show that I got anything wrong in that one. I hope that in a few months this video becomes out of date because the frameworks do a better job. Who knows? Well, I mentioned the newsletter and the Patreon earlier in the video, so I can just get straight to the 20 seconds of silence, some call awkward silence, that quite a few of you really love. Thanks so much for watching. Goodbye.')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is LoRA?\"\n",
    "vectorstore.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "  api_key=os.environ['OPENAI_API_KEY'],\n",
    "  azure_endpoint=os.environ['OPENAI_AZURE_ENDPOINT'],\n",
    "  api_version=os.environ['OPENAI_API_VERSION'],\n",
    "  azure_deployment=os.environ['OPENAI_AZURE_DEPLOYMENT']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = rag_chain.invoke({\"input\": \"What is the purpose of the video 'How to fine-tune a model using LoRA (step by step)'?\"})\n",
    "# response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = rag_chain.invoke({\"input\": \"Create an abstract of the video 'How to fine-tune a model using LoRA (step by step)'.\"})\n",
    "# response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Podcast Outline: Have You Picked the Wrong AI Agent Framework?\n",
      "\n",
      "#### 1. Introduction\n",
      "- Brief introduction of the podcast host(s)\n",
      "- Overview of the topic: AI agent frameworks and the common pitfalls\n",
      "- Mention the inspiration from the video \"Have You Picked the Wrong AI Agent Framework?\"\n",
      "\n",
      "#### 2. The Complexity of Current AI Agent Frameworks\n",
      "- Discussion on why current frameworks are considered verbose, complicated, and time-consuming\n",
      "- Examples of repetitive boilerplate code\n",
      "- Comparison to early Windows programming using the Charles Petzold book\n",
      "\n",
      "#### 3. Simplifying the Process: An Easier Way\n",
      "- Introduction to the simplified method showcased in the video\n",
      "- Benefits of using simpler methods: less code, fewer bugs, and quicker results\n",
      "\n",
      "#### 4. Case Study: Using CrewAI\n",
      "- Detailed walkthrough of the CrewAI example from the video\n",
      "  - Automating components of a YouTube strategy\n",
      "  - Tasks like researching topics, generating titles, descriptions, and emails\n",
      "- Discussion on the time savings and efficiency gained\n",
      "\n",
      "#### 5. Code Comparison\n",
      "- Comparison of code length: 60 lines of custom code vs. 300 lines using CrewAI\n",
      "- Highlighting the advantages of reduced code complexity\n",
      "\n",
      "#### 6. Practical Applications and User Feedback\n",
      "- Encouragement for listeners to automate their own workflows with AI\n",
      "- Request for listeners to share their experiences and strategies in the comments\n",
      "\n",
      "#### 7. Challenges and Future Prospects\n",
      "- Potential issues with current AI agent frameworks\n",
      "- Speculation on improvements and updates in the near future\n",
      "- Encouragement to stay updated with new developments in AI frameworks\n",
      "\n",
      "#### 8. Conclusion\n",
      "- Recap of the key points discussed\n",
      "- Final thoughts on the importance of choosing the right AI agent framework\n",
      "- Invitation to subscribe to the newsletter, Patreon, and provide feedback\n",
      "\n",
      "#### 9. Outro\n",
      "- Thank listeners for tuning in\n",
      "- Mention any upcoming episodes or related topics\n",
      "- Sign-off and closing remarks\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"Create an outline for a podcast based on the video \" + title + \".\"})\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"title\": \"Have You Picked the Wrong AI Agent Framework?\",\n",
      "  \"text\": [\n",
      "    {\n",
      "      \"speaker\": \"Pierre\",\n",
      "      \"intonation\": \"enthusiastic\",\n",
      "      \"text\": \"Welcome to the Advanced AI Podcast! I'm your host, Pierre, your go-to podcast assistant. Today, we have an exciting topic lined up: AI agent frameworks and the common pitfalls you might be facing. Inspired by the video 'Have You Picked the Wrong AI Agent Framework?' we're here to dive deep into this issue. Joining us is Marie, our expert on today's topic. Welcome, Marie!\"\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": \"Marie\",\n",
      "      \"intonation\": \"warm\",\n",
      "      \"text\": \"Thank you Pierre. It's great to be here. Today, we'll be discussing the complexity of current AI agent frameworks, how we can simplify the process, and we'll even look at a case study using CrewAI. We'll also compare code lengths and discuss practical applications and potential challenges in the future.\"\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": \"Pierre\",\n",
      "      \"intonation\": \"curious\",\n",
      "      \"text\": \"That sounds fascinating! So, Marie, why are current AI agent frameworks considered to be so complex, verbose, and time-consuming?\"\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": \"Marie\",\n",
      "      \"intonation\": \"informative\",\n",
      "      \"text\": \"Well, Pierre, many existing frameworks require a lot of repetitive boilerplate code, which can be quite cumbersome. It's a bit like early Windows programming where you had to type out extensive boilerplate just to get a simple 'Hello, World!' on the screen. This verbosity makes the development process more complicated and time-consuming than it needs to be.\"\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": \"Pierre\",\n",
      "      \"intonation\": \"interested\",\n",
      "      \"text\": \"I see. So, how does the method showcased in the video simplify this process?\"\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": \"Marie\",\n",
      "      \"intonation\": \"enthusiastic\",\n",
      "      \"text\": \"The video demonstrates a much simpler way to build AI agent workflows, often with significantly less code. Using simpler methods not only reduces the amount of code needed but also minimizes the risk of bugs and speeds up the development process. For instance, some tasks that would take 300 lines of code can be reduced to just 60 lines.\"\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": \"Pierre\",\n",
      "      \"intonation\": \"excited\",\n",
      "      \"text\": \"That sounds like a huge improvement! Can you walk us through the CrewAI example from the video?\"\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": \"Marie\",\n",
      "      \"intonation\": \"detailed\",\n",
      "      \"text\": \"Absolutely. In the video, CrewAI is used to automate parts of a YouTube strategy. It handles tasks like researching topics, generating possible titles and descriptions, and even drafting emails to send out to subscribers. This not only saves a lot of time but also increases efficiency. What could take hours manually is accomplished in seconds with CrewAI.\"\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": \"Pierre\",\n",
      "      \"intonation\": \"impressed\",\n",
      "      \"text\": \"That's truly impressive. So, how does the code length compare when using these simplified methods?\"\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": \"Marie\",\n",
      "      \"intonation\": \"clear\",\n",
      "      \"text\": \"The custom code example in the video is about 60 lines long, compared to 300 lines when using CrewAI. Less code usually means fewer bugs and easier maintenance, making the whole process more efficient.\"\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": \"Pierre\",\n",
      "      \"intonation\": \"encouraging\",\n",
      "      \"text\": \"This really highlights the advantages of reducing code complexity. Can you share some practical applications and how listeners might benefit from automating their workflows with AI?\"\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": \"Marie\",\n",
      "      \"intonation\": \"encouraging\",\n",
      "      \"text\": \"Certainly! I encourage listeners to look at their daily tasks and think about how they can automate them with AI. Whether it's managing emails, generating content, or any other repetitive task, AI can significantly streamline these processes. We'd love to hear your experiences and strategies, so please share them in the comments.\"\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": \"Pierre\",\n",
      "      \"intonation\": \"thoughtful\",\n",
      "      \"text\": \"That's great advice. What about the challenges and future prospects of AI agent frameworks?\"\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": \"Marie\",\n",
      "      \"intonation\": \"speculative\",\n",
      "      \"text\": \"There are definitely some challenges, such as handling edge cases and ensuring the reliability of automated tasks. However, I believe we will see significant improvements in AI frameworks in the near future, making them even more user-friendly and efficient. Staying updated with the latest developments is crucial.\"\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": \"Pierre\",\n",
      "      \"intonation\": \"concluding\",\n",
      "      \"text\": \"Thank you for those insights, Marie. To recap, we've discussed the complexities of current AI agent frameworks, how simpler methods can save time and reduce bugs, and we've looked at a practical example using CrewAI. It's clear that choosing the right AI agent framework is crucial for efficiency and success.\"\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": \"Marie\",\n",
      "      \"intonation\": \"grateful\",\n",
      "      \"text\": \"Thank you Pierre. It's been a pleasure discussing this important topic.\"\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": \"Pierre\",\n",
      "      \"intonation\": \"friendly\",\n",
      "      \"text\": \"Thank you Marie. And thank you to our listeners for tuning in. Don't forget to subscribe to our newsletter, join our Patreon, and leave your feedback. Stay tuned for upcoming episodes where we'll dive into more exciting AI topics. Until next time, this is Pierre signing off.\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Create a prompt with the outline to get a full podcast text\n",
    "podcast_outline = response['answer']\n",
    "podcast_prompt = f\"\"\"Create a podcast complete text based on the following outline:\n",
    "\n",
    "{podcast_outline}\n",
    "\n",
    "This text will be used to generate the audio of the podcast. There are 2 participants in the podcast: the host and the guest. The host will introduce the podcast and the guest. The guest will explain the outline of the podcast. The host will ask questions to the guest and the guest will answer them. The host will thank the guest and close the podcast.\n",
    "The name of the host is Pierre and his role is to be the listener's podcast assistant. The name of the guest is Marie and her role is to be the expert in the podcast topic. The name of the podcast is \"Advanced AI Podcast\".\n",
    "\n",
    "When you thanks someone, write \"Thank you\" and the name of the person without a comma. For example, \"Thank you Pierre\".\n",
    "\n",
    "Output as a JSON with the following fields:\n",
    "- title: Title of the podcast\n",
    "- text: an array of objects with the speaker, the intonation and the text to be spoken\n",
    "Return only the json as plain text.\n",
    "\"\"\"\n",
    "formatted_podcast_prompt = podcast_prompt.format(podcast_outline)\n",
    "\n",
    "podcast_script_response = rag_chain.invoke({\"input\": formatted_podcast_prompt})\n",
    "podcast_script_text = podcast_script_response['answer']\n",
    "print(podcast_script_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
      "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n",
      "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
      "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
      "ALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\n",
      "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n"
     ]
    }
   ],
   "source": [
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import json\n",
    "\n",
    "# Creates an instance of a speech config with specified subscription key and service region.\n",
    "speech_key = os.environ['AZURE_SPEECH_KEY']\n",
    "service_region = os.environ['AZURE_SPEECH_REGION']\n",
    "\n",
    "speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "\n",
    "# This is an example of SSML (Speech Synthesis Markup Language) format.\n",
    "# <speak version=\"1.0\" xmlns=\"https://www.w3.org/2001/10/synthesis\" xml:lang=\"en-US\">\n",
    "#   <voice name=\"en-US-AvaMultilingualNeural\">\n",
    "#     When you're on the freeway, it's a good idea to use a GPS.\n",
    "#   </voice>\n",
    "# </speak>\n",
    "# Parse the JSON response and create a SSML with en-US-GuyNeural for Pierre Voice\n",
    "# and en-US-JennyNeural for Marie Voice\n",
    "podcast_script_json = json.loads(str(podcast_script_text))\n",
    "ssml_text = \"<speak version='1.0' xmlns='https://www.w3.org/2001/10/synthesis' xml:lang='en-US'>\"\n",
    "for line in podcast_script_json['text']:\n",
    "    speaker = line['speaker']\n",
    "    text = line['text']\n",
    "    if speaker == 'Pierre':\n",
    "        ssml_text += f\"<voice name='en-US-GuyNeural'>{text}</voice>\"\n",
    "    elif speaker == 'Marie':\n",
    "        ssml_text += f\"<voice name='en-US-JennyNeural'>{text}</voice>\"\n",
    "ssml_text += \"</speak>\"\n",
    "\n",
    "# use the default speaker as audio output.\n",
    "speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config)\n",
    "\n",
    "result = speech_synthesizer.speak_ssml_async(ssml_text).get()\n",
    "stream = speechsdk.AudioDataStream(result)\n",
    "podcast_filename = fileName.split('.')[0] + '_podcast.wav'\n",
    "stream.save_to_wav_file(podcast_filename)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
